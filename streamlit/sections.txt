1.1 THE CHALLENGES OF NATURAL LANGUAGE PROCESSING
1.2 NEURAL NETWORKS AND DEEP LEARNING
1.3 DEEP LEARNING IN NLP
1.4 COVERAGE AND ORGANIZATION
1.5 WHAT'S NOT COVERED
1.6 A NOTE ON TERMINOLOGY
1.7 MATHEMATICAL NOTATION
2.1 SUPERVISED LEARNING AND PARAMETERIZED FUNCTIONS
2.2 TRAIN, TEST, AND VALIDATION SETS
2.3 LINEAR MODELS
2.4 REPRESENTATIONS
2.5 ONE-HOT AND DENSE VECTOR REPRESENTATIONS
2.6 LOG-LINEAR MULTI-CLASS CLASSIFICATION
2.7 TRAINING AS OPTIMIZATION
2.8 GRADIENT-BASED OPTIMIZATION
3.1 LIMITATIONS OF LINEAR MODELS: THE XOR PROBLEM
3.2 NONLINEAR INPUT TRANSFORMATIONS
3.3 KERNEL METHODS
3.4 TRAINABLE MAPPING FUNCTIONS
4.1 A BRAIN-INSPIRED METAPHOR
4.2 IN MATHEMATICAL NOTATION
4.3 REPRESENTATION POWER
4.4 COMMON NONLINEARITIES
4.5 LOSS FUNCTIONS
4.6 REGULARIZATION AND DROPOUT
4.7 SIMILARITY AND DISTANCE LAYERS
4.8 EMBEDDING LAYERS
5.1 THE COMPUTATION GRAPH ABSTRACTION
5.2 PRACTICALITIES
6.1 TYPOLOGY OF NLP CLASSIFICATION PROBLEMS
6.2 FEATURES FOR NLP PROBLEMS